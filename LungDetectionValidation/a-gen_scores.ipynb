{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e90faef-4c8f-4377-b94c-c23466003091",
   "metadata": {},
   "outputs": [],
   "source": [
    "### source: https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173\n",
    "### consider calculating the precision and recall of each exam + between all validation exams \n",
    "### also the precision-recall curve\n",
    "### also consider the recall-IoU curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792d5d6b-a9df-496b-8ebb-b6ec8ca32646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from generate_transforms import generate_detection_inference_transform\n",
    "from monai.apps.detection.networks.retinanet_detector import RetinaNetDetector\n",
    "from monai.apps.detection.utils.anchor_utils import AnchorGeneratorWithAnchorShape\n",
    "from monai.data import DataLoader, Dataset, load_decathlon_datalist\n",
    "from monai.data.utils import no_collation\n",
    "from monai.transforms import ScaleIntensityRanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c814fbb0-e825-4f42-9a60-c9e2e5fe827d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crawling-sloth-537.pth',\n",
       " 'indecisive-eel-172.pth',\n",
       " 'model.pth',\n",
       " 'overjoyed-hen-305.pth',\n",
       " 'powerful-goat-766.pth']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('/data/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f04779e-4d95-43ee-87c2-52c4c875add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_box_mode = \"cccwhd\"\n",
    "data_list_file_path = \"/data/output/mixed_data/mixed_test.json\"\n",
    "data_base_dir = \"/data/mixed/\"\n",
    "\n",
    "returned_layers = [1,2]\n",
    "base_anchor_shapes = [[6,8,4],[8,6,5],[10,10,6]]\n",
    "patch_size = [192,192,80]\n",
    "amp = True\n",
    "\n",
    "# model_path = \"/mlflow/5/93273c7eb040429a9470b98ebd6ffb12/artifacts/best_model/data/model.pth\"\n",
    "model_path = \"/data/models/overjoyed-hen-305.pth\"\n",
    "score_thresh = 0.02\n",
    "nms_thresh = 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ad6267-92cd-4e6a-a819-628625d695f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n"
     ]
    }
   ],
   "source": [
    "# testar com janelamento padrão, e mesmo do treinamento\n",
    "intensity_transform = ScaleIntensityRanged(\n",
    "    keys=[\"image\"],\n",
    "    a_min=-1000.0,\n",
    "    a_max=-200.0,\n",
    "    b_min=0.0,\n",
    "    b_max=1.0,\n",
    "    clip=True,\n",
    ")\n",
    "inference_transforms, post_transforms = generate_detection_inference_transform(\n",
    "    \"image\",\n",
    "    \"pred_box\",\n",
    "    \"pred_label\",\n",
    "    \"pred_score\",\n",
    "    gt_box_mode,\n",
    "    intensity_transform,\n",
    "    affine_lps_to_ras=True,\n",
    "    amp=amp,\n",
    ")\n",
    "inference_data = load_decathlon_datalist(\n",
    "    data_list_file_path,\n",
    "    is_segmentation=True,\n",
    "    data_list_key=\"test\",\n",
    "    base_dir=data_base_dir,\n",
    ")\n",
    "inference_ds = Dataset(\n",
    "    data=inference_data,\n",
    "    transform=inference_transforms,\n",
    ")\n",
    "inference_loader = DataLoader(\n",
    "    inference_ds,\n",
    "    batch_size=1,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    collate_fn=no_collation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d65479-7fb4-4bf4-a254-a9943442adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b13b4a-4d90-4bb1-b408-57ca0e8b07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_generator = AnchorGeneratorWithAnchorShape(\n",
    "    feature_map_scales=[2**l for l in range(len(returned_layers) + 1)],\n",
    "    base_anchor_shapes=base_anchor_shapes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0a4c63-2a90-4a17-b4ea-9e4567f3fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from /data/models/model.pth\n"
     ]
    }
   ],
   "source": [
    "net = torch.jit.load(model_path).to(device)\n",
    "print(f\"Load model from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef0cfdd-aeb2-4d68-890c-5f5c098ad6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = RetinaNetDetector(\n",
    "    network=net, anchor_generator=anchor_generator, debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd970676-06c4-491c-a3b5-b1707c8139ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.set_box_selector_parameters(\n",
    "    score_thresh=score_thresh,\n",
    "    topk_candidates_per_level=1000,\n",
    "    nms_thresh=nms_thresh,\n",
    "    detections_per_img=100,\n",
    ")\n",
    "detector.set_sliding_window_inferer(\n",
    "    roi_size=patch_size,\n",
    "    overlap=0.25,\n",
    "    sw_batch_size=1,\n",
    "    mode=\"gaussian\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b227cd1-6eee-4d33-b1ef-1e8e5c96ebb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [1:43:34<00:00, 40.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 28min 18s, sys: 6min 30s, total: 1h 34min 49s\n",
      "Wall time: 1h 43min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_dict = {\"test\": []}\n",
    "detector.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inference_data in tqdm(inference_loader):\n",
    "        inference_img_filenames = [\n",
    "            inference_data_i[\"image_meta_dict\"][\"filename_or_obj\"] for inference_data_i in inference_data\n",
    "        ]\n",
    "        use_inferer = not all(\n",
    "            [inference_data_i[\"image\"][0, ...].numel() < np.prod(patch_size) for inference_data_i in inference_data]\n",
    "        )\n",
    "        inference_inputs = [inference_data_i[\"image\"].to(device) for inference_data_i in inference_data]\n",
    "\n",
    "        if amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                inference_outputs = detector(inference_inputs, use_inferer=use_inferer)\n",
    "        else:\n",
    "            inference_outputs = detector(inference_inputs, use_inferer=use_inferer)\n",
    "        del inference_inputs\n",
    "\n",
    "        # update inference_data for post transform\n",
    "        for i in range(len(inference_outputs)):\n",
    "            inference_data_i, inference_pred_i = (\n",
    "                inference_data[i],\n",
    "                inference_outputs[i],\n",
    "            )\n",
    "            inference_data_i[\"pred_box\"] = inference_pred_i[detector.target_box_key].to(torch.float32)\n",
    "            inference_data_i[\"pred_label\"] = inference_pred_i[detector.target_label_key]\n",
    "            inference_data_i[\"pred_score\"] = inference_pred_i[detector.pred_score_key].to(torch.float32)\n",
    "            inference_data[i] = post_transforms(inference_data_i)\n",
    "\n",
    "        for inference_img_filename, inference_pred_i in zip(inference_img_filenames, inference_data):\n",
    "            result = {\n",
    "                \"label\": inference_pred_i[\"pred_label\"].cpu().detach().numpy().tolist(),\n",
    "                \"box\": inference_pred_i[\"pred_box\"].cpu().detach().numpy().tolist(),\n",
    "                \"score\": inference_pred_i[\"pred_score\"].cpu().detach().numpy().tolist(),\n",
    "            }\n",
    "            result.update({\"image\": inference_img_filename})\n",
    "            results_dict[\"test\"].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46369858-bc8c-49bc-9b1e-04e410494fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/data/output/validation/mixed_test2.json\", \"w\") as write_file:\n",
    "    json.dump(results_dict, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e67f50-f3c0-4593-ba57-3b0f0ed67441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
