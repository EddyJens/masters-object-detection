{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3167e6ea-ec92-400f-a405-d91cf3debe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ref: https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f58b7f0-31a9-45b3-aa95-265bb9812fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from utils import (\n",
    "    load_itk, world_to_pixel, any_match,\n",
    "    calc_iou, nms_pytorch\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa82a7d1-391a-4b6f-82fe-4f25e1278332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['true_box', 'pred_box', 'score', 'image'])\n"
     ]
    }
   ],
   "source": [
    "data_list_file_path = '/data/output/validation/test_parsed.json'\n",
    "f = open(data_list_file_path)\n",
    "data = json.load(f)\n",
    "\n",
    "print(data['test'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a870173a-a7aa-41fc-a1b3-09137d6e35e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([289.0000, 181.0000,  95.0000, 310.0000, 202.0000, 108.0000,   0.9873]), tensor([305.0000, 306.0000, 239.0000, 321.0000, 323.0000, 248.0000,   0.9238]), tensor([113.0000, 149.0000,  69.0000, 131.0000, 168.0000,  80.0000,   0.8281]), tensor([267.0000, 395.0000, 104.0000, 296.0000, 424.0000, 122.0000,   0.7998]), tensor([ 53.0000, 313.0000,  74.0000,  69.0000, 330.0000,  84.0000,   0.6953]), tensor([373.0000, 164.0000, 165.0000, 385.0000, 176.0000, 171.0000,   0.5596]), tensor([ 98.0000, 324.0000, 109.0000, 112.0000, 338.0000, 117.0000,   0.5503]), tensor([163.0000, 162.0000, 153.0000, 252.0000, 253.0000, 193.0000,   0.4102]), tensor([167.0000, 282.0000, 197.0000, 190.0000, 305.0000, 210.0000,   0.3281]), tensor([2.8200e+02, 4.3000e+02, 4.0000e+01, 3.0700e+02, 4.5400e+02, 5.5000e+01,\n",
      "        3.2275e-01]), tensor([1.1100e+02, 2.5600e+02, 1.6400e+02, 1.2600e+02, 2.7100e+02, 1.7400e+02,\n",
      "        2.4011e-01]), tensor([3.7200e+02, 2.6300e+02, 1.0900e+02, 3.8200e+02, 2.7400e+02, 1.1600e+02,\n",
      "        2.2803e-01]), tensor([1.2900e+02, 1.9500e+02, 4.4000e+01, 2.2400e+02, 2.8600e+02, 1.0500e+02,\n",
      "        1.7993e-01]), tensor([1.5100e+02, 1.6400e+02, 6.9000e+01, 1.7500e+02, 1.8700e+02, 8.3000e+01,\n",
      "        1.6333e-01]), tensor([1.0300e+02, 1.7900e+02, 8.1000e+01, 1.2300e+02, 1.9800e+02, 9.3000e+01,\n",
      "        1.4795e-01]), tensor([3.7000e+02, 1.9300e+02, 1.6400e+02, 3.8400e+02, 2.0700e+02, 1.7200e+02,\n",
      "        1.3000e-01]), tensor([3.1600e+02, 2.0600e+02, 1.2900e+02, 3.3600e+02, 2.2600e+02, 1.4100e+02,\n",
      "        1.0779e-01]), tensor([8.2000e+01, 3.3100e+02, 7.8000e+01, 1.2100e+02, 3.7000e+02, 1.0100e+02,\n",
      "        8.8013e-02]), tensor([3.7300e+02, 1.4600e+02, 2.4000e+01, 4.6100e+02, 2.3700e+02, 6.9000e+01,\n",
      "        8.7097e-02]), tensor([1.6700e+02, 2.6000e+02, 1.1500e+02, 1.9800e+02, 2.9500e+02, 1.3300e+02,\n",
      "        8.3740e-02]), tensor([2.9800e+02, 1.8700e+02, 7.3000e+01, 3.1300e+02, 2.0200e+02, 8.2000e+01,\n",
      "        7.3425e-02]), tensor([1.8400e+02, 1.6800e+02, 1.9500e+02, 1.9500e+02, 1.8000e+02, 2.0200e+02,\n",
      "        6.3354e-02]), tensor([2.4000e+02, 3.1700e+02, 2.2800e+02, 2.6700e+02, 3.4100e+02, 2.4300e+02,\n",
      "        6.1981e-02]), tensor([2.9900e+02, 2.7000e+02, 1.3500e+02, 3.1500e+02, 2.8700e+02, 1.4500e+02,\n",
      "        6.0516e-02]), tensor([2.9600e+02, 2.4200e+02, 9.9000e+01, 3.3800e+02, 2.8500e+02, 1.2500e+02,\n",
      "        5.8014e-02]), tensor([3.0000e+02, 1.7100e+02, 1.1500e+02, 3.2800e+02, 1.9600e+02, 1.2600e+02,\n",
      "        5.6976e-02]), tensor([3.3500e+02, 1.6200e+02, 1.8800e+02, 3.4700e+02, 1.7400e+02, 1.9600e+02,\n",
      "        5.6549e-02]), tensor([2.5300e+02, 3.6100e+02, 1.6900e+02, 2.8200e+02, 3.9000e+02, 1.8800e+02,\n",
      "        5.6244e-02]), tensor([3.1200e+02, 2.1600e+02, 1.1900e+02, 3.2200e+02, 2.2500e+02, 1.2300e+02,\n",
      "        4.2389e-02]), tensor([1.5900e+02, 1.6000e+02, 8.8000e+01, 1.8200e+02, 1.8400e+02, 1.0200e+02,\n",
      "        4.0375e-02]), tensor([9.0000e+01, 2.7900e+02, 6.0000e+00, 1.0200e+02, 2.9000e+02, 1.2000e+01,\n",
      "        3.6499e-02]), tensor([3.3500e+02, 1.8700e+02, 8.7000e+01, 3.6500e+02, 2.1600e+02, 1.0400e+02,\n",
      "        3.6224e-02]), tensor([3.0600e+02, 1.5600e+02, 1.6600e+02, 3.1800e+02, 1.6900e+02, 1.7100e+02,\n",
      "        3.5156e-02]), tensor([1.6500e+02, 1.7500e+02, 1.2700e+02, 1.8100e+02, 1.9100e+02, 1.3700e+02,\n",
      "        3.4821e-02]), tensor([3.0600e+02, 1.6400e+02, 7.8000e+01, 3.2700e+02, 1.8400e+02, 9.0000e+01,\n",
      "        3.1616e-02]), tensor([2.9300e+02, 2.5600e+02, 8.4000e+01, 3.0600e+02, 2.7000e+02, 9.1000e+01,\n",
      "        3.1204e-02]), tensor([1.3400e+02, 1.6000e+02, 2.0600e+02, 2.1900e+02, 2.5500e+02, 2.5900e+02,\n",
      "        3.0045e-02]), tensor([9.2000e+01, 1.9100e+02, 1.0800e+02, 1.0300e+02, 2.0300e+02, 1.1600e+02,\n",
      "        2.9419e-02]), tensor([3.9700e+02, 2.1100e+02, 1.4400e+02, 4.0800e+02, 2.2200e+02, 1.5100e+02,\n",
      "        2.8549e-02]), tensor([3.2700e+02, 2.5700e+02, 9.1000e+01, 3.4000e+02, 2.6900e+02, 9.9000e+01,\n",
      "        2.7176e-02]), tensor([2.9800e+02, 2.2900e+02, 1.6300e+02, 3.1200e+02, 2.4300e+02, 1.7100e+02,\n",
      "        2.6154e-02]), tensor([3.0500e+02, 1.0600e+02, 8.9000e+01, 3.2200e+02, 1.2300e+02, 9.9000e+01,\n",
      "        2.5085e-02]), tensor([6.3000e+01, 2.8400e+02, 8.8000e+01, 7.4000e+01, 2.9500e+02, 9.6000e+01,\n",
      "        2.5040e-02]), tensor([4.0500e+02, 1.9500e+02, 9.5000e+01, 4.1800e+02, 2.0800e+02, 1.0400e+02,\n",
      "        2.4384e-02]), tensor([2.3400e+02, 2.6900e+02, 2.4100e+02, 2.6000e+02, 2.9200e+02, 2.4700e+02,\n",
      "        2.3651e-02]), tensor([3.3000e+02, 2.1600e+02, 1.6900e+02, 3.4200e+02, 2.2900e+02, 1.7700e+02,\n",
      "        2.1866e-02])]\n",
      "0 [{'voxel_min': array([ 54, 314,  75]), 'voxel_max': array([ 68, 328,  83])}, {'voxel_min': array([290, 181,  95]), 'voxel_max': array([310, 201, 107])}]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# for content in tqdm(data['test']):\n",
    "for index, content in enumerate(data['test'][4:5]):\n",
    "\n",
    "    img, origin, spacing = load_itk(content['image'])\n",
    "    origin = np.array(list(reversed(origin)))\n",
    "    spacing = np.array(list(reversed(spacing)))\n",
    "\n",
    "    P = []\n",
    "    targets = []\n",
    "    \n",
    "    for true_box in content['true_box']:\n",
    "        world_coord_cent = np.array((true_box[0], true_box[1], true_box[2]))\n",
    "        world_coord_diam = np.array((true_box[3], true_box[4], true_box[5]))\n",
    "\n",
    "        voxel_min, voxel_max = world_to_pixel(\n",
    "            origin, spacing, world_coord_cent, world_coord_diam\n",
    "        )\n",
    "\n",
    "        targets.append({\n",
    "            \"voxel_min\": voxel_min.astype(int),\n",
    "            \"voxel_max\": voxel_max.astype(int)\n",
    "        })\n",
    "\n",
    "    for pred_box, score in zip(content['pred_box'], content['score']):\n",
    "\n",
    "        # if score > 0.2:\n",
    "        world_coord_cent = np.array((pred_box[0], pred_box[1], pred_box[2]))\n",
    "        world_coord_diam = np.array((pred_box[3], pred_box[4], pred_box[5]))\n",
    "\n",
    "        voxel_min, voxel_max = world_to_pixel(\n",
    "            origin, spacing, world_coord_cent, world_coord_diam\n",
    "        )\n",
    "\n",
    "        P.append([\n",
    "            voxel_min[0].astype(int), \n",
    "            voxel_min[1].astype(int), \n",
    "            voxel_min[2].astype(int),\n",
    "            voxel_max[0].astype(int), \n",
    "            voxel_max[1].astype(int), \n",
    "            voxel_max[2].astype(int),\n",
    "            score\n",
    "        ])\n",
    "\n",
    "    ### calculate NMS\n",
    "    filtered_boxes = nms_pytorch(torch.tensor(P), 1e-45)\n",
    "    print(filtered_boxes)\n",
    "\n",
    "    if len(targets) > 1:\n",
    "        print(index, targets)\n",
    "\n",
    "    ### calculate IoU for each exam\n",
    "    # area_overlap = 0\n",
    "    # area_union = 0\n",
    "    # for prediction in predictions:\n",
    "    #     for target in targets:\n",
    "    #         if any_match(prediction, target):\n",
    "    #             metrics.append({\n",
    "    #                 \"image\": content['image'],\n",
    "    #                 \"IoU\": calc_iou(target, prediction)\n",
    "    #             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804f71b-aa31-479b-9a02-122272ec31e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
