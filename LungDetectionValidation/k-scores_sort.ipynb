{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from utils import (\n",
    "    calc_iou, any_match,\n",
    "    gen_froc_plot, gen_tabular_data,\n",
    "    convert_to_tensor\n",
    ")\n",
    "from monai.data.box_utils import non_max_suppression\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'pixel-parsed-mixed_test-overjoyed-hen-305',\n",
    "    'pixel-parsed-mixed_test-indecisive-eel-172',\n",
    "    'pixel-parsed-mixed_test-powerful-goat-766',\n",
    "    'pixel-parsed-mixed_test-crawling-sloth-537',\n",
    "    'pixel-parsed-all'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 41.46it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 36.88it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 34.05it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 42.84it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 39.72it/s]\n"
     ]
    }
   ],
   "source": [
    "all_fps_per_image = []\n",
    "all_total_sensitivity = []\n",
    "tabular_data = []\n",
    "all_testy = []\n",
    "all_lr_probs = []\n",
    "\n",
    "composed_tp, composed_fp, composed_fn = 0, 0, 0\n",
    "composed_tp_probs = []\n",
    "composed_testy = []\n",
    "composed_lr_probs = []\n",
    "composed_fp_probs = []\n",
    "\n",
    "wrong_ones = []\n",
    "\n",
    "for file_name in files:\n",
    "    output_path = '/data/output/validation/each_window/hc/'\n",
    "\n",
    "    data_list_file_path = f'{output_path}{file_name}.json'\n",
    "\n",
    "    f = open(data_list_file_path)\n",
    "    data = json.load(f)\n",
    "\n",
    "    iou_thresh = 0.5\n",
    "    num_images = 21\n",
    "    num_targets = 27\n",
    "\n",
    "    fp_probs = []\n",
    "    tp_probs = []\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    testy = []\n",
    "    lr_probs = []\n",
    "\n",
    "    for content in tqdm(data['test']):\n",
    "        converted = convert_to_tensor(content['pred_box'])\n",
    "\n",
    "        keep = non_max_suppression(\n",
    "            converted, torch.tensor(content['score']), nms_thresh=0.1, max_proposals=100\n",
    "        )\n",
    "\n",
    "        boxes_after_nms = [content['pred_box'][index] for index in keep]\n",
    "        scores_after_nms = torch.tensor(content['score'])[keep]\n",
    "\n",
    "        for pred_box, score in zip(boxes_after_nms, scores_after_nms):\n",
    "            # if score > 0.5:\n",
    "            iou = 0\n",
    "            if any_match(content['true_box'][0], pred_box):\n",
    "                iou = calc_iou(content['true_box'][0], pred_box)\n",
    "            if iou >= iou_thresh:\n",
    "                tp += 1\n",
    "                tp_probs.append(score)\n",
    "                composed_tp += 1\n",
    "                composed_tp_probs.append(score)\n",
    "\n",
    "                testy.append(1)\n",
    "                lr_probs.append(score)\n",
    "                composed_testy.append(1)\n",
    "                composed_lr_probs.append(score)\n",
    "            if iou < iou_thresh and iou > 0:\n",
    "                fp += 1\n",
    "                fp_probs.append(score)\n",
    "                composed_fp += 1\n",
    "                composed_fp_probs.append(score)\n",
    "\n",
    "                testy.append(0)\n",
    "                lr_probs.append(score)\n",
    "                composed_testy.append(0)\n",
    "                composed_lr_probs.append(score)\n",
    "\n",
    "                wrong_ones.append(content['image'])\n",
    "            \n",
    "            if iou == 0:\n",
    "                fn += 1\n",
    "                composed_fn += 1\n",
    "\n",
    "                testy.append(0)\n",
    "                lr_probs.append(score)\n",
    "                composed_testy.append(0)\n",
    "                composed_lr_probs.append(score)\n",
    "\n",
    "                wrong_ones.append(content['image'])\n",
    "\n",
    "    fps_per_image, total_sensitivity, precision, recall, p1, p2, p3, p4, p5, p6 ,p7, cpm = gen_tabular_data(\n",
    "        tp, fp, fn, fp_probs, tp_probs, num_images, num_targets\n",
    "    )\n",
    "\n",
    "    all_fps_per_image.append(fps_per_image)\n",
    "    all_total_sensitivity.append(total_sensitivity)\n",
    "    all_testy.append(testy)\n",
    "    all_lr_probs.append(lr_probs)\n",
    "\n",
    "    tabular_data.append({\n",
    "        \"1/8\": p1,\n",
    "        \"2/8\": p2,\n",
    "        \"4/8\": p3,\n",
    "        \"1\": p4,\n",
    "        \"2\": p5,\n",
    "        \"4\": p6,\n",
    "        \"8\": p7,\n",
    "        \"CPM\": cpm\n",
    "    })\n",
    "\n",
    "first_table = pd.DataFrame(tabular_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to select the most \"wrong\" exam, all fp where printed, and the most frequent was selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10322\n"
     ]
    }
   ],
   "source": [
    "print(len(wrong_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz',\n",
       " '/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_ones[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['/data/HC_Images_resample/PL155113087338785/PL155113087338785.nii.gz', '/data/HC_Images_resample/PL969252002286674/PL969252002286674.nii.gz', '/data/HC_Images_resample/PL153971807430236/PL153971807430236.nii.gz', '/data/HC_Images_resample/PL206802585657179/PL206802585657179.nii.gz', '/data/HC_Images_resample/PL316898027619487/PL316898027619487.nii.gz', '/data/HC_Images_resample/PL559798186095424/PL559798186095424.nii.gz', '/data/HC_Images_resample/PL421132963270314/PL421132963270314.nii.gz', '/data/HC_Images_resample/PL657447059971795/PL657447059971795.nii.gz', '/data/HC_Images_resample/PL245366064520387/PL245366064520387.nii.gz', '/data/HC_Images_resample/PL217160176826976/PL217160176826976.nii.gz', '/data/HC_Images_resample/PL620133077537220/PL620133077537220.nii.gz', '/data/HC_Images_resample/PL652297908013408/PL652297908013408.nii.gz', '/data/HC_Images_resample/PL926008951016659/PL926008951016659.nii.gz', '/data/HC_Images_resample/PL606729492858408/PL606729492858408.nii.gz', '/data/HC_Images_resample/PL883384319849708/PL883384319849708.nii.gz', '/data/HC_Images_resample/PL061850842690412/PL061850842690412.nii.gz', '/data/HC_Images_resample/PL637340825227915/PL637340825227915.nii.gz', '/data/HC_Images_resample/PL482296892847501/PL482296892847501.nii.gz', '/data/HC_Images_resample/PL952806205422554/PL952806205422554.nii.gz', '/data/HC_Images_resample/PL156124271286723/PL156124271286723.nii.gz', '/data/HC_Images_resample/PL145353604730560/PL145353604730560.nii.gz'])\n",
      "dict_values([494, 495, 495, 494, 457, 499, 490, 495, 455, 494, 496, 497, 495, 495, 494, 495, 495, 499, 495, 493, 500])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(wrong_ones).keys())\n",
    "print(Counter(wrong_ones).values()) # counts the elements' frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
